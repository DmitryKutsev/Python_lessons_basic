{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DmitryKutsev/Python_lessons_basic/blob/master/BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG_gtye9xkfW",
        "colab_type": "text"
      },
      "source": [
        "Check out [this issue](https://github.com/hanxiao/bert-as-service/issues/380) and \"make sure Colab is using Tensorflow 1.x, because bert-serving-start doesn't currently work with TF 2.1 and nohup hides the output of the command failing\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acWmlZeroAC3",
        "colab_type": "code",
        "outputId": "01e74f26-be23-407e-a1c9-bf81c870aeca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print (tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5eP2_kNhvFf",
        "colab_type": "code",
        "outputId": "fe431afe-8612-4af7-e552-6f964d53ea32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        }
      },
      "source": [
        "!pip install -U bert-serving-server[http]\n",
        "!pip install bert-serving-client  # client, independent of `bert-serving-server`"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-server[http]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\r\u001b[K     |█████▎                          | 10kB 34.4MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 20kB 5.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 30kB 8.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 40kB 5.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 51kB 6.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 5.8MB/s \n",
            "\u001b[?25hCollecting GPUtil>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Collecting pyzmq>=17.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/07/cee3d328a2e13f9de1c2b62cced7a389b61ac81424f2e377f3dc9d668282/pyzmq-18.1.1-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 26.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.17.5)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: flask; extra == \"http\" in /usr/local/lib/python3.6/dist-packages (from bert-serving-server[http]) (1.1.1)\n",
            "Collecting flask-compress; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/0e/2a/378bd072928f6d92fd8c417d66b00c757dc361c0405a46a0134de6fd323d/Flask-Compress-1.4.0.tar.gz\n",
            "Collecting flask-cors; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/78/38/e68b11daa5d613e3a91e4bf3da76c94ac9ee0d9cd515af9c1ab80d36f709/Flask_Cors-3.0.8-py2.py3-none-any.whl\n",
            "Collecting flask-json; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/2d/4c21d98b11f3a206fabbdd965b53a2ca3ee9fab7646c93cf36c060e8f1a4/Flask_JSON-0.3.4-py3-none-any.whl\n",
            "Collecting bert-serving-client; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (7.0)\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (2.11.1)\n",
            "Requirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from Jinja2>=2.10.1->flask; extra == \"http\"->bert-serving-server[http]) (1.1.1)\n",
            "Building wheels for collected packages: GPUtil, flask-compress\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp36-none-any.whl size=7413 sha256=d00c14f40ffd416c84d7b745cd34380c316f22b859edadaecc6c5c8e491a9578\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "  Building wheel for flask-compress (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for flask-compress: filename=Flask_Compress-1.4.0-cp36-none-any.whl size=3712 sha256=dff3a54e7fb6c3c5e11b6bfc1b9752b4c0bcf4b69edb2b2b0f1e637b4d5cb228\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/32/88/a1f6d9dd3c29570ab3a8acc0d556b3b20abcf3c623c868ce0a\n",
            "Successfully built GPUtil flask-compress\n",
            "Installing collected packages: GPUtil, pyzmq, flask-compress, flask-cors, flask-json, bert-serving-client, bert-serving-server\n",
            "  Found existing installation: pyzmq 17.0.0\n",
            "    Uninstalling pyzmq-17.0.0:\n",
            "      Successfully uninstalled pyzmq-17.0.0\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-client-1.10.0 bert-serving-server-1.10.0 flask-compress-1.4.0 flask-cors-3.0.8 flask-json-0.3.4 pyzmq-18.1.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "zmq"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-serving-client in /usr/local/lib/python3.6/dist-packages (1.10.0)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (18.1.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from bert-serving-client) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gePhcxaviZj7",
        "colab_type": "code",
        "outputId": "ef82aace-d4de-4cd6-b75b-b27d4761048a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "!unzip /content/multi_cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-02-21 08:34:05--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.126.128, 2a00:1450:4013:c00::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.126.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662903077 (632M) [application/zip]\n",
            "Saving to: ‘multi_cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "multi_cased_L-12_H- 100%[===================>] 632.19M  80.4MB/s    in 8.7s    \n",
            "\n",
            "2020-02-21 08:34:14 (72.6 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip’ saved [662903077/662903077]\n",
            "\n",
            "Archive:  /content/multi_cased_L-12_H-768_A-12.zip\n",
            "   creating: multi_cased_L-12_H-768_A-12/\n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pKKkhNVjhXH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nohup bert-serving-start -model_dir=./multi_cased_L-12_H-768_A-12 > out.file 2>&1 &"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oW2AyjWJkZNz",
        "colab_type": "code",
        "outputId": "eac7b0a4-5cdf-4c15-d51f-56386de2dfef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "from bert_serving.client import BertClient\n",
        "bc = BertClient()\n",
        "encoded_test = bc.encode(['First do it', 'then do it right', 'then do it better'])\n",
        "encoded_test"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.49155664,  0.08795999,  0.08263218, ...,  1.0980442 ,\n",
              "         0.41126633, -0.25396997],\n",
              "       [-0.07413427, -0.22783546, -0.08978209, ...,  1.5093107 ,\n",
              "         1.3512002 , -0.03158389],\n",
              "       [-0.26575196,  0.19135582, -0.35613608, ...,  1.396217  ,\n",
              "         1.4187478 ,  0.12651809]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6TgFi28z3YR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for vec in encoded_test:\n",
        "  print (len(vec))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyhO3vSB21-N",
        "colab_type": "code",
        "outputId": "da5b8963-e5d9-45d8-dce7-5a445fa9de2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# bc.server_status"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ckpt_name': 'bert_model.ckpt',\n",
              " 'client': '8470f7d1-898f-450a-bd36-241f6cb1583e',\n",
              " 'config_name': 'bert_config.json',\n",
              " 'cors': '*',\n",
              " 'cpu': False,\n",
              " 'device_map': [],\n",
              " 'do_lower_case': True,\n",
              " 'fixed_embed_length': False,\n",
              " 'fp16': False,\n",
              " 'gpu_memory_fraction': 0.5,\n",
              " 'graph_tmp_dir': None,\n",
              " 'http_max_connect': 10,\n",
              " 'http_port': None,\n",
              " 'mask_cls_sep': False,\n",
              " 'max_batch_size': 256,\n",
              " 'max_seq_len': 25,\n",
              " 'model_dir': './multi_cased_L-12_H-768_A-12',\n",
              " 'no_position_embeddings': False,\n",
              " 'no_special_token': False,\n",
              " 'num_concurrent_socket': 8,\n",
              " 'num_process': 2,\n",
              " 'num_worker': 1,\n",
              " 'pooling_layer': [-2],\n",
              " 'pooling_strategy': 2,\n",
              " 'port': 5555,\n",
              " 'port_out': 5556,\n",
              " 'prefetch_size': 10,\n",
              " 'priority_batch_size': 16,\n",
              " 'python_version': '3.6.9 (default, Nov  7 2019, 10:44:02) \\n[GCC 8.3.0]',\n",
              " 'pyzmq_version': '18.1.1',\n",
              " 'server_current_time': '2020-02-20 23:11:52.452719',\n",
              " 'server_start_time': '2020-02-20 22:48:22.895601',\n",
              " 'server_version': '1.10.0',\n",
              " 'show_tokens_to_client': False,\n",
              " 'statistic': {'avg_last_two_interval': 167.19920086919998,\n",
              "  'avg_request_per_client': 7.0,\n",
              "  'avg_request_per_second': 0.012916794467380453,\n",
              "  'avg_size_per_request': 2.2,\n",
              "  'max_last_two_interval': 362.44887896700016,\n",
              "  'max_request_per_client': 7,\n",
              "  'max_request_per_second': 0.02087549192551614,\n",
              "  'max_size_per_request': 3,\n",
              "  'min_last_two_interval': 47.90306276699994,\n",
              "  'min_request_per_client': 7,\n",
              "  'min_request_per_second': 0.0027590097749786305,\n",
              "  'min_size_per_request': 2,\n",
              "  'num_active_client': 0,\n",
              "  'num_data_request': 5,\n",
              "  'num_max_last_two_interval': 1,\n",
              "  'num_max_request_per_client': 1,\n",
              "  'num_max_request_per_second': 1,\n",
              "  'num_max_size_per_request': 1,\n",
              "  'num_min_last_two_interval': 1,\n",
              "  'num_min_request_per_client': 1,\n",
              "  'num_min_request_per_second': 1,\n",
              "  'num_min_size_per_request': 1,\n",
              "  'num_sys_request': 2,\n",
              "  'num_total_client': 1,\n",
              "  'num_total_request': 7,\n",
              "  'num_total_seq': 11},\n",
              " 'tensorflow_version': ['1', '15', '0'],\n",
              " 'tuned_model_dir': None,\n",
              " 'ventilator -> worker': ['ipc://tmpQGv2EH/socket',\n",
              "  'ipc://tmppDpQiR/socket',\n",
              "  'ipc://tmpdXeFW0/socket',\n",
              "  'ipc://tmpD26uAa/socket',\n",
              "  'ipc://tmpC1Ulek/socket',\n",
              "  'ipc://tmpCN8eSt/socket',\n",
              "  'ipc://tmpOsm9vD/socket',\n",
              "  'ipc://tmpWds49M/socket'],\n",
              " 'ventilator <-> sink': 'ipc://tmp1hAf1x/socket',\n",
              " 'verbose': False,\n",
              " 'worker -> sink': 'ipc://tmp3Rxmhv/socket',\n",
              " 'xla': False,\n",
              " 'zmq_version': '4.3.2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    }
  ]
}